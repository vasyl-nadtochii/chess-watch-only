Ý

x*

 €R
linear_1*	
Ü €¢­¢9
#com.github.apple.coremltools.sourcetorch==2.5.1+cu121¢+
$com.github.apple.coremltools.version8.1¢@
+com.github.apple.coremltools.source_dialectTorchExport::ATEN²›'¢%
main™%
#
x




CoreML5è$
CoreML5Ü$linear_1h
const
conv2d_pad_type_0
*'
name

"
conv2d_pad_type_0*
val


"
customl
const
conv2d_pad_0


*"
name

"
conv2d_pad_0*!
val





r
const 
conv2d_strides_0


*&
name

"
conv2d_strides_0*
val




v
const"
conv2d_dilations_0


*(
name 

"
conv2d_dilations_0*
val




_
const
conv2d_groups_0
*%
name

"
conv2d_groups_0*
val


f
const
x_to_fp16_dtype_0
*'
name

"
x_to_fp16_dtype_0*
val


"
fp16¼
const8
p_conv1_weight_to_fp16


@


*,
name$

"
p_conv1_weight_to_fp16*K
valD


@


*"
@model_path/weights/weight.bin@•
const$
p_conv1_bias_to_fp16



@**
name"

"
p_conv1_bias_to_fp16*:
val3



@*#
@model_path/weights/weight.bin€v}
cast
dtype

x_to_fp16_dtype_0

x

x+
	x_to_fp16





*
name


"
cast_2ß
conv$
weight

p_conv1_weight_to_fp16#
	dilations

conv2d_dilations_0
groups

conv2d_groups_0
pad

conv2d_pad_0 
bias

p_conv1_bias_to_fp16
strides

conv2d_strides_0
x

	x_to_fp16!
pad_type

conv2d_pad_type_02
conv2d_cast_fp16



@

*&
name

"
conv2d_cast_fp16y
relu
x

conv2d_cast_fp160
relu_cast_fp16



@

*$
name

"
relu_cast_fp16l
const
conv2d_1_pad_type_0
*)
name!

"
conv2d_1_pad_type_0*
val


"
customp
const
conv2d_1_pad_0


*$
name

"
conv2d_1_pad_0*!
val





v
const"
conv2d_1_strides_0


*(
name 

"
conv2d_1_strides_0*
val




z
const$
conv2d_1_dilations_0


**
name"

"
conv2d_1_dilations_0*
val




c
const
conv2d_1_groups_0
*'
name

"
conv2d_1_groups_0*
val


¿
const9
p_conv2_weight_to_fp16


€
@

*,
name$

"
p_conv2_weight_to_fp16*M
valF


€
@

*#
@model_path/weights/weight.binÀw˜
const%
p_conv2_bias_to_fp16


€**
name"

"
p_conv2_bias_to_fp16*<
val5


€*$
@model_path/weights/weight.bin€ø	ó
conv$
weight

p_conv2_weight_to_fp16%
	dilations

conv2d_1_dilations_0
groups

conv2d_1_groups_0
pad

conv2d_1_pad_0 
bias

p_conv2_bias_to_fp16!
strides

conv2d_1_strides_0
x

relu_cast_fp16#
pad_type

conv2d_1_pad_type_05
conv2d_1_cast_fp16



€

*(
name 

"
conv2d_1_cast_fp16€
relu
x

conv2d_1_cast_fp163
relu_1_cast_fp16



€

*&
name

"
relu_1_cast_fp16a
const
const_4


*
name

"	
const_4* 
val


	

€@‡
reshape
x

relu_1_cast_fp16
shape
	
const_4%
view_cast_fp16



€@*$
name

"
view_cast_fp16¦
const,
p_fc1_weight_to_fp16


€
€@**
name"

"
p_fc1_weight_to_fp16*C
val<


€
€@*$
@model_path/weights/weight.binÀú	•
const#
p_fc1_bias_to_fp16


€*(
name 

"
p_fc1_bias_to_fp16*=
val6


€*%
@model_path/weights/weight.bin€û‰º
linear"
weight

p_fc1_weight_to_fp16
bias

p_fc1_bias_to_fp16
x

view_cast_fp16)
linear_0_cast_fp16



€*(
name 

"
linear_0_cast_fp16t
relu
x

linear_0_cast_fp16'
relu_2_cast_fp16



€*&
name

"
relu_2_cast_fp16§
const,
p_fc2_weight_to_fp16


Ü
€**
name"

"
p_fc2_weight_to_fp16*D
val=


Ü
€*%
@model_path/weights/weight.binÀÿ‰•
const#
p_fc2_bias_to_fp16


Ü*(
name 

"
p_fc2_bias_to_fp16*=
val6


Ü*%
@model_path/weights/weight.bin€ðÄ¼
linear"
weight

p_fc2_weight_to_fp16
bias

p_fc2_bias_to_fp16
x

relu_2_cast_fp16)
linear_1_cast_fp16



Ü*(
name 

"
linear_1_cast_fp16ˆ
const*
"linear_1_cast_fp16_to_fp32_dtype_0
*8
name0
(
&"$
"linear_1_cast_fp16_to_fp32_dtype_0*
val


"
fp32“
cast/
dtype&
$
"linear_1_cast_fp16_to_fp32_dtype_0
x

linear_1_cast_fp16
linear_1


Ü*
name


"
cast_1"ñ
	buildInfoã"


Ð"Í
6
!

"
coremltools-version
	
"
8.1
F
)
!
"
coremltools-component-torch

"
2.5.1+cu121
K
(
 
"
coremltools-source-dialect

"
TorchExport::ATEN